{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy in Python for Natural Language Processing (NLP) Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook and Code from https://github.com/jeffheaton/t81_558_deep_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sonnet 18 original text\n",
      "William Shakespeare\n",
      "\n",
      "Shall I compare thee to a summer's day?\n",
      "Thou art more lovely and more temperate:\n",
      "Rough winds do shake the darling buds of May,\n",
      "And summer's lease hath all too short a date:\n",
      "Sometime too hot the eye of heaven shines,\n",
      "And often is his gold complexion dimm'd;\n",
      "And every fair from fair sometime declines,\n",
      "By chance or nature's changing course untrimm'd;\n",
      "But thy eternal summer shall not fade\n",
      "Nor lose possession of that fair thou owest;\n",
      "Nor shall Death brag thou wander'st in his shade,\n",
      "When in eternal lines to time thou growest:\n",
      "So long as men can breathe or eyes can see,\n",
      "So long lives this and this gives life to thee.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "url = \"https://data.heatonresearch.com/data/t81-558/datasets/sonnet_18.txt\"\n",
    "with urllib.request.urlopen(url) as urlstream:\n",
    "    for line in codecs.iterdecode(urlstream, 'utf-8'):\n",
    "        print(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So\n",
      "long\n",
      "lives\n",
      "this\n",
      "and\n",
      "this\n",
      "gives\n",
      "life\n",
      "to\n",
      "thee\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(line.rstrip())\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "a\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(u\"Apple is looking at buying a U.K. startup for $1 billion\")\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also obtain the part of speech for each word.  Common parts of speech include nouns, verbs, pronouns, and adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN\n",
      "is AUX\n",
      "looking VERB\n",
      "at ADP\n",
      "buying VERB\n",
      "a DET\n",
      "U.K. PROPN\n",
      "startup NOUN\n",
      "for ADP\n",
      "$ SYM\n",
      "1 NUM\n",
      "billion NUM\n"
     ]
    }
   ],
   "source": [
    "for word in doc:  \n",
    "    print(word.text,  word.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy includes functions to check if parts of a sentence appear to be numbers, acronyms, or other entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple is like number? False\n",
      "is is like number? False\n",
      "looking is like number? False\n",
      "at is like number? False\n",
      "buying is like number? False\n",
      "a is like number? False\n",
      "U.K. is like number? False\n",
      "startup is like number? False\n",
      "for is like number? False\n",
      "$ is like number? False\n",
      "1 is like number? True\n",
      "billion is like number? True\n"
     ]
    }
   ],
   "source": [
    "for word in doc:\n",
    "    print(f\"{word} is like number? {word.like_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gao/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"59271a8d04444cc784037ba93a790341-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sentance</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-59271a8d04444cc784037ba93a790341-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-59271a8d04444cc784037ba93a790341-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-59271a8d04444cc784037ba93a790341-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-59271a8d04444cc784037ba93a790341-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-59271a8d04444cc784037ba93a790341-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-59271a8d04444cc784037ba93a790341-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(u\"This is a sentance\")\n",
    "displacy.serve(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note, you will have to manually stop the above cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentance\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows how to reduce words to their stems.  Here the sentence words are reduced to their most basic form.  For example, \"striped\" to \"stripe.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the stripe bat be hang on -PRON- foot for good'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger \n",
    "# component needed for lemmatization\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "\n",
    "# Parse the sentence using the loaded 'en' model object `nlp`\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Extract the lemma for each token and join\n",
    "\n",
    "\" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'moreover', 'does', 'becomes', 'though', 'done', 'often', 'all', 'next', 'sometime', 'show', 'your', 'forty', 'am', 'on', 'however', 'empty', '’m', 'again', 'have', 'up', 'six', 'any', 'ours', 'may', 'mine', 'not', 'upon', 'top', 'twenty', 'please', 'latter', 'noone', 'this', 'make', 'former', 'wherein', 'hereupon', 'nevertheless', \"'ll\", 'less', 'nowhere', 'side', 'via', 'whatever', '’s', 'becoming', 'onto', 'by', 'being', 'n‘t', 'should', 'themselves', 'almost', 'rather', 'nor', 'once', 'hence', 'few', 'unless', 'along', 'off', 'everyone', 'put', 'fifty', 'one', 'hereby', 'neither', 'anyhow', 'whom', '‘ve', 'it', 'give', 'seemed', '‘s', 'or', 'first', 'is', \"'ve\", 'everything', 'per', 'front', 'whose', 'whoever', 'three', '’re', 'just', 'could', 'beyond', 'none', 'below', 'you', 'thereupon', 'wherever', 'full', 'a', 'whereupon', 'go', 'then', 'although', 'has', 'yet', 'we', 'call', 'something', 'ten', 'using', 'anything', 'until', 'two', 'but', '‘d', 'now', 'amongst', 'serious', 'if', 'already', 'some', 'me', 'their', 'latterly', 'part', 'further', 'between', 'down', 'get', 'namely', 'more', 'nothing', 'do', 'back', 'anywhere', 'hers', 'become', 'there', 'always', 'eight', 'anyway', 'sixty', '’ll', 'around', 'alone', 'who', 'move', 'over', 'well', 'yourself', 'in', \"'d\", 'else', 'about', 'name', 'without', 'therefore', 'thence', 'anyone', '‘m', 'least', 'had', \"'m\", 'see', 'last', 'beside', 'i', 'cannot', 're', 'she', 'therein', 'made', 'must', 'own', 'they', 'became', 'are', 'other', 'at', 'someone', 'never', 'while', 'here', 'when', 'meanwhile', 'each', 'ever', 'his', 'five', 'thru', 'somewhere', 'itself', 'what', 'only', 'than', 'very', 'under', 'many', 'whole', '’d', 'say', 'together', 'most', 'seeming', 'ca', 'where', '‘ll', 'eleven', 'among', 'our', 'otherwise', 'of', 'out', 'myself', 'keep', 'her', 'might', 'really', 'why', 'an', 'against', 'him', 'thereby', 'were', 'twelve', 'towards', \"n't\", 'can', 'so', 'also', 'whither', 'hundred', 'seems', 'thereafter', 'whereby', 'behind', 'whether', 'ourselves', 'formerly', 'either', 'afterwards', 'its', 'various', 'whereafter', 'mostly', 'doing', 'those', 'to', 'nobody', 'perhaps', 'with', 'too', 'these', 'seem', 'toward', 'third', 'into', 'be', 'bottom', 'the', 'enough', 'amount', 'four', 'regarding', 'which', 'even', 'before', 'them', 'same', 'after', 'that', 'will', 'would', 'hereafter', 'elsewhere', 'through', 'how', 'whence', '‘re', 'above', 'take', 'indeed', 'whereas', 'from', 'himself', 'did', 'quite', 'herein', 'he', 'yours', 'was', 'because', 'herself', 'us', 'thus', 'during', 'everywhere', 'been', \"'re\", 'another', 'no', 'several', 'much', 'due', 'throughout', 'within', 'still', 'except', 'n’t', 'as', 'my', 'whenever', 'fifteen', 'besides', 'sometimes', 'used', 'nine', \"'s\", 'across', 'somehow', 'yourselves', 'both', 'others', 'for', 'every', 'such', 'and', 'since', 'beforehand', '’ve'}\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "print(STOP_WORDS)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
